CIC {
  CIC_OAUTH_KEY = ""
  CIC_REGION = ""
  CIC_APPID = "xx"
}
discover {
  eu {
    #eu_spark_template_simple_url = "https://eu.liveapps.cloud.tibco.com/webresource/orgFolders/"${CIC_APPID}"_assets/processMinerSimple_template.json"
    #eu_spark_env_url = "https://eu.liveapps.cloud.tibco.com/webresource/orgFolders/"${CIC_APPID}"_assets/environment.json"
    #eu_spark_template_scheduled_url = "https://eu.liveapps.cloud.tibco.com/webresource/orgFolders/"${CIC_APPID}"_assets/processMinerScheduled_template.json"
    #eu_shared_state_config_url = "https://eu.liveapps.cloud.tibco.com/clientstate/v1/states?%24filter=name%20eq%20'"${CIC_APPID}".discover.config.client.context.SHARED'"
    eu_claims_url = "https://eu.liveapps.cloud.tibco.com/organisation/v1/claims"
    eu_groups_details_url = "https://eu.liveapps.cloud.tibco.com/organisation/v1/users/" #11743/groups?%24sandbox=3100&%24top=1000
  }
}
K8S {
  name = "labs-discover-spark-pm"
  domain = "tibcosoftware"
  version = "0.1"
  template = "/opt/orchestator/labs-discover-spark.template.json"
}
server {
  host = localhost
  port = 8080
}
storage {
  host = localhost
  port = 5432
  dbName = trips
  url = "jdbc:postgresql://"${storage.host}":"${storage.port}"/"${storage.dbName}
  driver = "org.postgresql.Driver"
  user = "postgres"
  password = "something"
  connectionTimeout = 3000
  maximumPoolSize = 100
}
#akka {
#  loglevel = "DEBUG"
#  actor.provider = cluster
#
#  coordinated-shutdown.exit-jvm = on
#  cluster {
#    shutdown-after-unsuccessful-join-seed-nodes = 120s
#  }
#}
akka {
  actor {
    default-dispatcher {
      fork-join-executor {
        parallelism-min = 1
        parallelism-max = 64
        parallelism-factor = 1
      }
      throughput = 64
    }
  }

  http {
    host-connection-pool {
      max-connections = 10000
      max-open-requests = 4096
    }

    server {
      pipelining-limit = 1024
      max-connections = 4096
      backlog = 1024
    }
  }
}
akka.server.parsing.max-content-length = 1g
#management-config
#akka.management {
#  cluster.bootstrap {
#    contact-point-discovery {
#      # pick the discovery method you'd like to use:
#      discovery-method = kubernetes-api
#      required-contact-point-nr = ${REQUIRED_CONTACT_POINT_NR}
#    }
#  }
#}
#management-config
#akka.management {
#  cluster.bootstrap {
#    contact-point-discovery {
#      discovery-method = kubernetes-api
#
#      required-contact-point-nr = ${REQUIRED_CONTACT_POINT_NR}
#    }
#  }
#  http {
#    port = 8558
#    bind-hostname = "0.0.0.0"
#    bind-port = 8558
#  }
#}
#management-config

#akka.management {
#  health-checks {
#    readiness-checks {
#      example-ready = "com.tibco.labs.orchestrator.node.cluster.HealthCheck"
#    }
#  }
#}

my-app {
  routes {
    # If ask takes more time than this to complete the request is failed
    ask-timeout = 5s
  }
}
processmining {
  routes {
    # If ask takes more time than this to complete the request is failed
    ask-timeout = 10s
  }
}
files {
  routes {
    # If ask takes more time than this to complete the request is failed
    ask-timeout = 900s
  }
}

tdv {
  routes {
    # If ask takes more time than this to complete the request is failed
    ask-timeout = 60s
  }
}

########################################
# akka-http-cors Reference Config File #
########################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

akka-http-cors {

  # If enabled, allow generic requests (that are outside the scope of the specification)
  # to pass through the directive. Else, strict CORS filtering is applied and any
  # invalid request will be rejected.
  allow-generic-http-requests = yes

  # Indicates whether the resource supports user credentials.  If enabled, the header
  # `Access-Control-Allow-Credentials` is set in the response, indicating that the
  # actual request can include user credentials. Examples of user credentials are:
  # cookies, HTTP authentication or client-side certificates.
  allow-credentials = yes

  # List of origins that the CORS filter must allow. Can also be set to `*` to allow
  # access to the resource from any origin. Controls the content of the
  # `Access-Control-Allow-Origin` response header: if parameter is `*` and credentials
  # are not allowed, a `*` is set in `Access-Control-Allow-Origin`. Otherwise, the
  # origins given in the `Origin` request header are echoed.
  #
  # Hostname starting with `*.` will match any sub-domain.
  # The scheme and the port are always strictly matched.
  #
  # The actual or preflight request is rejected if any of the origins from the request
  # is not allowed.
  allowed-origins = "*"

  # List of request headers that can be used when making an actual request. Controls
  # the content of the `Access-Control-Allow-Headers` header in a preflight response:
  # if parameter is `*`, the headers from `Access-Control-Request-Headers` are echoed.
  # Otherwise the parameter list is returned as part of the header.
  allowed-headers = "*"

  # List of methods that can be used when making an actual request. The list is
  # returned as part of the `Access-Control-Allow-Methods` preflight response header.
  #
  # The preflight request will be rejected if the `Access-Control-Request-Method`
  # header's method is not part of the list.
  allowed-methods = ["GET", "POST", "HEAD", "OPTIONS", "PUT", "DELETE"]

  # List of headers (other than simple response headers) that browsers are allowed to access.
  # If not empty, this list is returned as part of the `Access-Control-Expose-Headers`
  # header in the actual response.
  exposed-headers = []

  # When set, the amount of seconds the browser is allowed to cache the results of a preflight request.
  # This value is returned as part of the `Access-Control-Max-Age` preflight response header.
  # If `null`, the header is not added to the preflight response.
  max-age = 1800 seconds
}
akka.http.parsing {
    max-to-strict-bytes = 1024m
  }
alpakka.s3 {
  # whether the buffer request chunks (up to 5MB each) to "memory" or "disk"
  buffer = "memory"

  # location for temporary files, if buffer is set to "disk". If empty, uses the standard java temp path.
  disk-buffer-path = ""

  # DEPRECATED since Alpakka 1.0.1
  # Please use alpakka.s3.endpoint-url for setting custom scheme, host and port.
  proxy {
    # hostname of the proxy. If undefined ("") proxy is not enabled.
    host = ""
    port = 8000

    # if "secure" is set to "true" then HTTPS will be used for all requests to S3, otherwise HTTP will be used
    secure = true
  }

  # An address of a proxy that will be used for all connections using HTTP CONNECT tunnel.
  # forward-proxy {
  #   scheme = "https"
  #   host = "proxy"
  #   port = 8080
  #   credentials {
  #     username = "username"
  #     password = "password"
  #   }
  # }

  # default values for AWS configuration
  aws {
    # If this section is absent, the fallback behavior is
    # to use the same configuration as if credentials.provider = default
    credentials {
      # anonymous requests (no auth)
      #
      # provider = anon

      # static credentials
      #
      # provider = static
      # access-key-id = ""
      # secret-access-key = ""
      # token = "" # optional

      # default: as described in software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider docs,
      # attempts to get the credentials from either:
      #   - environment variables
      #   - system properties
      #   - credentials file
      #   - EC2 credentials service
      #   - IAM / metadata
      provider = default
    }

    # If this section is absent, the fallback behavior is
    # to use the same configuration as if region.provider = default
    region {
      # static credentials
      #
      # provider = static
      #
      # This can be set to the `id` value of any of the regions defined in
      # software.amazon.awssdk.regions.Region
      # default-region = ""

      # default: as described in software.amazon.awssdk.regions.providers.DefaultAwsRegionProviderChain docs,
      # attempts to get the region from either:
      #   - environment variables
      #   - system properties
      #   - progile file
      #   - EC2 metadata
      provider = default
    }
  }

  # DEPRECATED (since Alpakka 2.0.0)
  # AWS S3 is going to retire path-style access, thus prefer the virtual-host-style access
  # https://aws.amazon.com/blogs/aws/amazon-s3-path-deprecation-plan-the-rest-of-the-story/
  #
  # Also, prefer to use the newer access-style property.
  #
  # Possible values:
  #  - false: use virtual-host style access
  #  - true: use legacy path-style access, warnings will be logged
  #  - force: use legacy path-style access, disable warnings
  #  - empty, null or absent (default): use `access-style`, which in turn defaults to virtual-host style access
  # path-style-access = false

  # Which access style to use. Prefer to use this setting over path-style-access.
  # Path-style access has been deprecated by Amazon and will not work on buckets created after September 30, 2020.
  # For alternative S3 implementations (MinIO, Rados Gateway, etc.), path-style access may continue to be required.
  # Possible values:
  #  - virtual: virtual host-style access, i.e. https://<bucket name>.s3.amazonaws.com/file/inside/bucket
  #  - path: path-style access, i.e. https://<region>.amazonaws.com/<bucket>/file/inside/bucket
  access-style = virtual

  # Custom endpoint url, used for alternate s3 implementations
  # To enable virtual-host-style access with Alpakka S3 use the placeholder `{bucket}` in the URL
  # eg. endpoint-url = "http://{bucket}.s3minio.alpakka:9000"
  #
  # endpoint-url = null

  # Which version of the list bucket api to use. Set to 1 to use the old style version 1 API.
  # By default the newer version 2 api is used.
  list-bucket-api-version = 2

  # Object keys are validated to NOT use sub-directory selection with `..` to improve security.
  # This flag may disable the validation.
  # See https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html
  validate-object-key = true

  # Default settings corresponding to automatic retry of requests in an S3 stream.
  retry-settings {
    # The maximum number of additional attempts (following transient errors) that will be made to process a given
    # request before giving up.
    max-retries = 3

    # The minimum delay between request retries.
    min-backoff = 200ms

    # The maximum delay between request retries.
    max-backoff = 10s

    # Random jitter factor applied to retry delay calculation.
    random-factor = 0.0
  }

  # Settings specific to S3 multipart uploads.
  multipart-upload {

    retry-settings = ${alpakka.s3.retry-settings}
  }
}