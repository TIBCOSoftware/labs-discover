scalaVersion := "2.12.12"
val postgresVersion = "42.2.16"
//https://akka.io/
lazy val akkaVersion = "2.6.4"

libraryDependencies ++= Seq(
  "com.typesafe.akka" %% "akka-actor-typed" % akkaVersion,
  "com.typesafe.akka" %% "akka-stream" % akkaVersion,
  "ch.qos.logback" % "logback-classic" % "1.2.3",
  "com.typesafe.akka" %% "akka-actor-testkit-typed" % akkaVersion % Test,
  "org.scalatest" %% "scalatest" % "3.1.0" % Test,
  "com.typesafe.scala-logging" %% "scala-logging" % "3.9.2"
)

// circe support - https://github.com/circe/circe
val circeVersion = "0.13.0"
libraryDependencies ++= Seq(
  "io.circe" %% "circe-core",
  "io.circe" %% "circe-generic",
  "io.circe" %% "circe-parser",
  "io.circe" %% "circe-optics",
  "io.circe" %% "circe-literal"
).map(_ % circeVersion)
//https://github.com/pathikrit/better-files
libraryDependencies += "com.github.pathikrit" % "better-files_2.12" % "3.8.0"

// STTP - HTTP client

libraryDependencies ++= List(
  "com.softwaremill.sttp.client" %% "okhttp-backend" % "2.2.9",
  "com.softwaremill.sttp.client" %% "circe" % "2.2.9",
  "com.softwaremill.sttp.client" %% "core" % "2.2.9"
)

//JDBC

libraryDependencies ++= Seq(
  "org.postgresql" % "postgresql" % postgresVersion
)


lazy val commonSettings = Seq(
  organization := "com.tibco.labs",
  scalaVersion := "2.12.12",
  version := "3.7"
)

// Settings
val domain = "tibcosoftware"

// For building the FAT jar
lazy val assemblySettings = Seq(
  assembly / assemblyOption := (assemblyOption in assembly).value.copy(includeScala = false),
  assembly / assemblyOutputPath := baseDirectory.value / "output" / s"${domain}-${name.value}.jar"
)


val targetDockerJarPath =  "/opt/orchestrator/"

// For building the docker image

lazy val dockerSettings = Seq(
  imageNames in docker := Seq(
    ImageName(s"$domain/${name.value}:latest"),
    ImageName(s"$domain/${name.value}:${version.value}")
  ),
  buildOptions in docker := BuildOptions(
    cache = false,
    removeIntermediateContainers = BuildOptions.Remove.Always,
    pullBaseImage = BuildOptions.Pull.Always
  ),
  dockerfile in docker := {
    // The assembly task generates a fat JAR file
    val artifact: File = assembly.value
    val artifactTargetPath = s"$targetDockerJarPath/$domain-${name.value}.jar"
    new Dockerfile {
      from(s"tibcosoftware/labs-discover-spark-eks:1.0")
    }.add(artifact, artifactTargetPath)
  }
)


// Include "provided" dependencies back to default run task
lazy val runLocalSettings = Seq(
  // https://stackoverflow.com/questions/18838944/how-to-add-provided-dependencies-back-to-run-test-tasks-classpath/21803413#21803413
  Compile / run := Defaults
    .runTask(
      fullClasspath in Compile,
      mainClass in (Compile, run),
      runner in (Compile, run)
    )
    .evaluated
)

lazy val root = (project in file("."))
  .enablePlugins(sbtdocker.DockerPlugin)
  .enablePlugins(AshScriptPlugin)
  .settings(
    commonSettings,
    assemblySettings,
    dockerSettings,
    runLocalSettings,
    name := "labs-discover-spark-orchestrator",
    Compile / mainClass := Some("com.tibco.labs.Orchestrator"),
    Compile / resourceGenerators += createSparkOrchestratorYAML.taskValue
  )


// Task to create helm chart
lazy val createSparkOrchestratorYAML: Def.Initialize[Task[Seq[File]]] = Def.task {
  val k8sFile = baseDirectory.value / "k8s" / s"${name.value}.yaml"

  val k8sContents =
    s"""# Generated by build.sbt. Please don't manually update, or do it at your own risks ;-)
       |apiVersion: apps/v1beta1
       |kind: Deployment
       |metadata:
       |  name: process-mining-orchestrator
       |  namespace: spark-operator
       |  annotations:
       |    iam.amazonaws.com/role: eksctl-k8s-nodegroup-k8s-minions-NodeInstanceRole-1JV6TDYIHBEBR
       |spec:
       |  replicas: 1
       |  revisionHistoryLimit: 1
       |  template:
       |    metadata:
       |      labels:
       |        app: spark-orchestrator
       |      namespace: spark-operator
       |    spec:
       |      serviceAccountName: spark-operator-spark
       |      containers:
       |        - name: process-mining-orchestrator
       |          envFrom:
       |          - configMapRef:
       |              name: orchestrator-discover-config
       |          args:
       |            - "$targetDockerJarPath/$domain-${name.value}.jar"
       |            - "${(Compile / run / mainClass).value.getOrElse("__MAIN_CLASS__")}"
       |          image: $domain/${name.value}:${version.value}
       |          imagePullPolicy: Always
       |          volumeMounts:
       |            - mountPath: /opt/orchestrator/templates/
       |              readOnly: true
       |              name: template
       |      imagePullSecrets:
       |      - name: regcred
       |      volumes:
       |      - name: template
       |          configMap:
       |            name: orchestrator-discover-config
       |            items:
       |            - key: labs-discover-spark.template.json
       |              path: labs-discover-spark.template.json
       |""".stripMargin

  IO.write(k8sFile, k8sContents)
  Seq(k8sFile)
}